{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Best Practices with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Writing Efficient Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining \"efficient\":      \n",
    "\n",
    "Efficient code satisfy 2 key concepts:      \n",
    "1) minimal completion time (fast runtime)       \n",
    "2) minimal resource consumption (small memory footprint)        \n",
    "i.e. reduce latency and memory overhead.      \n",
    "\n",
    "Defining \"Pythonic\":       \n",
    "\n",
    "Pythonic code tend to be less verbose and easier to interpret. (e.g. use list comprehension rather than for loop + append). Pythonic code is usually efficient code.        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to collect the names in the above list that have six letters or more. In other programming languages, the typical approach is to create an index variable (i), use i to iterate over the list, and use an if statement to collect the names with six letters or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Jerry', 'Kramer', 'Elaine', 'George', 'Newman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kramer', 'Elaine', 'George', 'Newman']\n"
     ]
    }
   ],
   "source": [
    "# Print the list created using the Non-Pythonic approach\n",
    "i = 0\n",
    "new_list= []\n",
    "while i < len(names):\n",
    "    if len(names[i]) >= 6:\n",
    "        new_list.append(names[i])\n",
    "    i += 1\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kramer', 'Elaine', 'George', 'Newman']\n"
     ]
    }
   ],
   "source": [
    "# more pythonic\n",
    "# Print the list created by looping over the contents of names\n",
    "better_list = []\n",
    "for name in names:\n",
    "    if len(name) >= 6:\n",
    "        better_list.append(name)\n",
    "print(better_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kramer', 'Elaine', 'George', 'Newman']\n"
     ]
    }
   ],
   "source": [
    "# best pythonic\n",
    "# Print the list created by using list comprehension\n",
    "best_list = [name for name in names if len(name) >= 6]\n",
    "print(best_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Building with built-ins\n",
    "\n",
    "Built-in components are referred to as the Python Standard Library.        \n",
    "Built-in types: list, tuple, set, dict and others.       \n",
    "Built-in func: print(), len(), range(), round(), enumerate(), map(), zip() etc.       \n",
    "Built-in module: os, sys, itertools, collections, math etc.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# range()\n",
    "# Explicitly typing a list of numbers:\n",
    "# nums = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# using range(start,stop) and list\n",
    "nums = range(0,11)\n",
    "nums_list = list(nums)\n",
    "print(nums_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# range(stop)\n",
    "nums = range(11)\n",
    "nums_list = list(nums)\n",
    "print(nums_list)\n",
    "\n",
    "# note that range func returns a range object, which we can convert into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# range() with a step value\n",
    "even_nums = range(2,11,2)\n",
    "even_nums_list = list(even_nums)\n",
    "print(even_nums_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'a'), (1, 'b'), (2, 'c'), (3, 'd')]\n"
     ]
    }
   ],
   "source": [
    "# enumerate()\n",
    "# enumerate() creates an index item pair for each item in the object provided.\n",
    "letters = [\"a\", \"b\", \"c\", \"d\"]\n",
    "indexed_letters = enumerate(letters)\n",
    "\n",
    "indexed_letters_list = list(indexed_letters)\n",
    "print(indexed_letters_list)\n",
    "\n",
    "# enumerate will return an enumerate object, then can be converted into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 'a'), (6, 'b'), (7, 'c'), (8, 'd')]\n"
     ]
    }
   ],
   "source": [
    "# enumerate with starting index\n",
    "letters = [\"a\", \"b\", \"c\", \"d\"]\n",
    "indexed_letters2 = enumerate(letters, start=5)\n",
    "\n",
    "indexed_letters2_list = list(indexed_letters2)\n",
    "print(indexed_letters2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 3, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "# map()\n",
    "# map applies a function to each element in an object\n",
    "\n",
    "nums = [1.5, 2.3, 3.4, 4.6, 5.0]\n",
    "\n",
    "rnd_nums = map(round, nums)\n",
    "print(list(rnd_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "# map() with lambda func.\n",
    "nums = [1,2,3,4,5]\n",
    "sqrd_nums = map(lambda x: x**2, nums)\n",
    "\n",
    "print(list(sqrd_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'range'>\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "[1, 3, 5, 7, 9, 11]\n"
     ]
    }
   ],
   "source": [
    "# Create a range object that goes from 0 to 5\n",
    "nums = range(0,6)\n",
    "print(type(nums))\n",
    "\n",
    "# Convert nums to a list\n",
    "nums_list = list(nums)\n",
    "print(nums_list)\n",
    "\n",
    "# Create a new list of odd numbers from 1 to 11 by unpacking a range object\n",
    "nums_list2 = [*range(1,12,2)]\n",
    "print(nums_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose you had a list of people that arrived at a party you are hosting. The list is ordered by arrival (Jerry was the first to arrive, followed by Kramer, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Jerry'), (1, 'Kramer'), (2, 'Elaine'), (3, 'George'), (4, 'Newman')]\n"
     ]
    }
   ],
   "source": [
    "names = ['Jerry', 'Kramer', 'Elaine', 'George', 'Newman']\n",
    "# non-pythonic way\n",
    "indexed_names = []\n",
    "for i in range(len(names)):\n",
    "    index_name = (i, names[i])\n",
    "    indexed_names.append(index_name)\n",
    "    \n",
    "print(indexed_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Jerry'), (1, 'Kramer'), (2, 'Elaine'), (3, 'George'), (4, 'Newman')]\n",
      "[(0, 'Jerry'), (1, 'Kramer'), (2, 'Elaine'), (3, 'George'), (4, 'Newman')]\n",
      "[(1, 'Jerry'), (2, 'Kramer'), (3, 'Elaine'), (4, 'George'), (5, 'Newman')]\n"
     ]
    }
   ],
   "source": [
    "# more pythonic\n",
    "# Rewrite the for loop to use enumerate\n",
    "indexed_names = []\n",
    "for i,name in enumerate(names):\n",
    "    index_name = (i,name)\n",
    "    indexed_names.append(index_name) \n",
    "print(indexed_names)\n",
    "\n",
    "# even more pythonic\n",
    "# Rewrite the above for loop using list comprehension\n",
    "indexed_names_comp = [(i,name) for i,name in enumerate(names)]\n",
    "print(indexed_names_comp)\n",
    "\n",
    "# very pythonic\n",
    "# Unpack an enumerate object with a starting index of one\n",
    "indexed_names_unpack = [*enumerate(names, start=1)]\n",
    "print(indexed_names_unpack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to create a new list (called names_uppercase) that converted all the letters in each name to uppercase. you could accomplish this with the below for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JERRY', 'KRAMER', 'ELAINE', 'GEORGE', 'NEWMAN']\n"
     ]
    }
   ],
   "source": [
    "names = ['Jerry', 'Kramer', 'Elaine', 'George', 'Newman']\n",
    "\n",
    "# not so pythonic\n",
    "names_uppercase = []\n",
    "\n",
    "for name in names:\n",
    "  names_uppercase.append(name.upper())\n",
    "\n",
    "print(names_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'map'>\n",
      "['JERRY', 'KRAMER', 'ELAINE', 'GEORGE', 'NEWMAN']\n"
     ]
    }
   ],
   "source": [
    "# Use map to apply str.upper to each element in names\n",
    "names_map  = map(str.upper, names)\n",
    "\n",
    "# Print the type of the names_map\n",
    "print(type(names_map))\n",
    "\n",
    "# Unpack names_map into a list\n",
    "names_uppercase = [*names_map]\n",
    "\n",
    "# Print the list created above\n",
    "print(names_uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 The power of NumPy arrays\n",
    "\n",
    "NumPy arrays provide a fast and memory efficient alternative to Python list.         \n",
    "numpy arrays are homogeneous, means they must contain elements of the same type.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "nums_list = list(range(5))\n",
    "print(nums_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "nums_np = np.array(range(5))\n",
    "print(nums_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "int64\n",
      "[1.  2.5 3. ]\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# np array homogeneity\n",
    "nums_np_ints = np.array([1,2,3])\n",
    "print(nums_np_ints)\n",
    "\n",
    "print(nums_np_ints.dtype)\n",
    "\n",
    "nums_np_floats = np.array([1,2.5,3])\n",
    "print(nums_np_floats)\n",
    "\n",
    "print(nums_np_floats.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 0, 1, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np array broadcasting\n",
    "nums_np = np.array([-2,-1,0,1,2])\n",
    "nums_np**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "[1, 4]\n",
      "[1 4]\n"
     ]
    }
   ],
   "source": [
    "# 2-D list/array comparison\n",
    "\n",
    "# list\n",
    "nums2 = [[1,2,3],\n",
    "       [4,5,6]]\n",
    "\n",
    "# array \n",
    "nums_np = np.array(nums2)\n",
    "\n",
    "# list slicing\n",
    "print(nums2[0][1])\n",
    "# array slicing\n",
    "print(nums_np[0,1])\n",
    "\n",
    "#return first col of list\n",
    "print([row[0] for row in nums2])\n",
    "\n",
    "# return first col of array\n",
    "print(nums_np[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# np boolean indexing\n",
    "nums = [-2, -1, 0, 1, 2]\n",
    "nums_np = np.array(nums)\n",
    "\n",
    "# bool mask\n",
    "print(nums_np > 0)\n",
    "\n",
    "print(nums_np[nums_np > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a list of guests (the names list). Each guest, for whatever reason, has decided to show up to the party in 10-minute increments. For example, Jerry shows up to Festivus 10 minutes into the party's start time, Kramer shows up 20 minutes into the party, and so on and so forth.        \n",
    "\n",
    "We want to write a few simple lines of code, using the built-ins we have covered, to welcome each of your guests and let them know how many minutes late they are to your party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Jerry', 'Kramer', 'Elaine', 'George', 'Newman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30, 40, 50]\n",
      "[ 7 17 27 37 47]\n",
      "[('Jerry', 7), ('Kramer', 17), ('Elaine', 27), ('George', 37), ('Newman', 47)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of arrival times\n",
    "arrival_times = [*range(10,60,10)]\n",
    "\n",
    "print(arrival_times)\n",
    "\n",
    "# clock is 3 min faster\n",
    "# Convert arrival_times to an array and update the times\n",
    "arrival_times_np = np.array(arrival_times)\n",
    "new_times = arrival_times_np - 3\n",
    "print(new_times)\n",
    "\n",
    "# Use list comprehension and enumerate to pair guests to new times\n",
    "guest_arrivals = [(names[i],time) for i,time in enumerate(new_times)]\n",
    "print(guest_arrivals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Runtime and profiling code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "magic command: enhancement on top of normal python syntax. They are prefix \"%\"         \n",
    "\n",
    "IPython has magic command %timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.58 µs ± 272 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rand_nums = np.random.rand(1000)\n",
    "# no. of run: how many iteration we want to estimate runtime (-r)\n",
    "# no. of loop: how many times the code is executed per run (-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.14 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "29.7 µs ± 20 µs per loop (mean ± std. dev. of 2 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r2 -n10 rand_nums = np.random.rand(1000)\n",
    "# 2 runs each with 10 execution, i.e. 20 times is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639 ns ± 12.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# single line of code\n",
    "%timeit nums = [x for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple lines of code\n",
    "# %%timeit\n",
    "# nums=[]\n",
    "# for x in range(10):\n",
    "#     nums.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 µs ± 115 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "9.11 µs ± 115 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# saving the timeit output\n",
    "times = %timeit -o rand_nums = np.random.rand(1000)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.049733690001176e-06,\n",
       " 9.209603429999334e-06,\n",
       " 9.222254799999519e-06,\n",
       " 9.297384989999955e-06,\n",
       " 9.01004766999904e-06,\n",
       " 9.014614130001063e-06,\n",
       " 8.998615220000374e-06]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times.timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.998615220000374e-06"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.297384989999955e-06"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times.worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 ns ± 1.07 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "33.3 ns ± 0.873 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# python data structure creation\n",
    "\n",
    "# using formal name\n",
    "formal_list = list()\n",
    "formal_dict = dict()\n",
    "formal_tuple = tuple()\n",
    "\n",
    "# using (shorthand) literal syntax\n",
    "literal_list = []\n",
    "literal_dict = {}\n",
    "literal_tuple = ()\n",
    "\n",
    "# compare timing of creation\n",
    "# formal\n",
    "f_time = %timeit -o formal_dict = dict()\n",
    "\n",
    "# literal\n",
    "l_time = %timeit -o literal_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.68 µs ± 12.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "534 ns ± 5 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Create a list of integers (0-50) using list comprehension\n",
    "%timeit nums_list_comp = [num for num in range(51)]\n",
    "\n",
    "# Create a list of integers (0-50) by unpacking range\n",
    "%timeit nums_unpack = [*range(51)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Code profiling for runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to time a large code base or see line-by-line within a function ? -> code profiling      \n",
    "\n",
    "Code Profiling is a technique used to describe how ling, and how often, various parts of a program are executed.    \n",
    "It can be used for line-by-line analysis, and provide stats on individual pieces of our code w/o magic command %timeit.       \n",
    "\n",
    "package used: line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = [\"Batman\", \"Superman\", \" Wonder Woman\"]\n",
    "\n",
    "hts = np.array([188.0, 191.0, 183.0])\n",
    "wts = np.array([95.0, 101.0, 74.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units(heroes, heights, weights):\n",
    "    new_hts = [ht*0.39370 for ht in heights]\n",
    "    new_wts = [wt*0.39370 for wt in weights]\n",
    "    \n",
    "    hero_data = {}\n",
    "    \n",
    "    for i,hero in enumerate(heroes):\n",
    "        hero_data[hero] = (new_hts[i], new_wts[i])\n",
    "        \n",
    "    return hero_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Batman': (74.01559999999999, 37.4015),\n",
       " 'Superman': (75.19669999999999, 39.7637),\n",
       " ' Wonder Woman': (72.0471, 29.1338)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_units(heroes, hts, wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.73 µs ± 25.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# use %timeit\n",
    "%timeit convert_units(heroes, hts, wts)\n",
    "# this only give us total execution time\n",
    "# we could technically use %timeit on every line in the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use line_profiler extension\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 2.9e-05 s\n",
       "File: <ipython-input-38-57a50ec7a699>\n",
       "Function: convert_units at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def convert_units(heroes, heights, weights):\n",
       "     2         1         16.0     16.0     55.2      new_hts = [ht*0.39370 for ht in heights]\n",
       "     3         1          5.0      5.0     17.2      new_wts = [wt*0.39370 for wt in weights]\n",
       "     4                                               \n",
       "     5         1          1.0      1.0      3.4      hero_data = {}\n",
       "     6                                               \n",
       "     7         4          4.0      1.0     13.8      for i,hero in enumerate(heroes):\n",
       "     8         3          3.0      1.0     10.3          hero_data[hero] = (new_hts[i], new_wts[i])\n",
       "     9                                                   \n",
       "    10         1          0.0      0.0      0.0      return hero_data"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# magic command %lprun is from line_profiler\n",
    "# -f: we want to profile a func\n",
    "# follow by the name of the func, w/o ().\n",
    "# then the func with arg\n",
    "%lprun -f convert_units convert_units(heroes, hts, wts)\n",
    "# hits: how many time that line is executed\n",
    "# time: uses time unit\n",
    "# per hit: avg amt of time spent executing a single line: Time/Hits\n",
    "# % Time: percentage of time spent on a line wrt total time in the func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units_broadcast(heroes, heights, weights):\n",
    "\n",
    "    # Array broadcasting instead of list comprehension\n",
    "    new_hts = heights * 0.39370\n",
    "    new_wts = weights * 2.20462\n",
    "\n",
    "    hero_data = {}\n",
    "\n",
    "    for i,hero in enumerate(heroes):\n",
    "        hero_data[hero] = (new_hts[i], new_wts[i])\n",
    "\n",
    "    return hero_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 2.4e-05 s\n",
       "File: <ipython-input-43-097b3089decf>\n",
       "Function: convert_units_broadcast at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def convert_units_broadcast(heroes, heights, weights):\n",
       "     2                                           \n",
       "     3                                               # Array broadcasting instead of list comprehension\n",
       "     4         1         16.0     16.0     66.7      new_hts = heights * 0.39370\n",
       "     5         1          4.0      4.0     16.7      new_wts = weights * 2.20462\n",
       "     6                                           \n",
       "     7         1          0.0      0.0      0.0      hero_data = {}\n",
       "     8                                           \n",
       "     9         4          1.0      0.2      4.2      for i,hero in enumerate(heroes):\n",
       "    10         3          3.0      1.0     12.5          hero_data[hero] = (new_hts[i], new_wts[i])\n",
       "    11                                           \n",
       "    12         1          0.0      0.0      0.0      return hero_data"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f convert_units_broadcast convert_units_broadcast(heroes, hts, wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Code profiling for memory usage\n",
    "\n",
    "can use built-in module: sys.     \n",
    "This module contains system specific func and contains a nice method: sys.getsizeof(nums_list), which return the size of the object in bytes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8096"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single obj size\n",
    "nums_np = np.array(range(1000))\n",
    "sys.getsizeof(nums_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file <ipython-input-38-57a50ec7a699>\n",
      "NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# line-by-line memory footprint\n",
    "%load_ext memory_profiler\n",
    "\n",
    "%mprun -f convert_units convert_units(heroes, hts, wts)\n",
    "# any func profiled for memory must be defined in a file and imported. so here wont work\n",
    "# so have to save in .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /Users/XavierTang/Documents/Data Science/Python/python_basics/hero_funcs.py\n",
       "\n",
       "Line #    Mem usage    Increment   Line Contents\n",
       "================================================\n",
       "     1     96.6 MiB     96.6 MiB   def convert_units(heroes, heights, weights):\n",
       "     2     96.6 MiB      0.0 MiB       new_hts = [ht*0.39370 for ht in heights]\n",
       "     3     96.6 MiB      0.0 MiB       new_wts = [wt*0.39370 for wt in weights]\n",
       "     4                                 \n",
       "     5     96.6 MiB      0.0 MiB       hero_data = {}\n",
       "     6                                 \n",
       "     7     96.6 MiB      0.0 MiB       for i,hero in enumerate(heroes):\n",
       "     8     96.6 MiB      0.0 MiB           hero_data[hero] = (new_hts[i], new_wts[i])\n",
       "     9                                     \n",
       "    10     96.6 MiB      0.0 MiB       return hero_data"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hero_funcs import convert_units\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "%mprun -f convert_units convert_units(heroes, hts, wts)\n",
    "\n",
    "# results will be differeent on different platform and runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Combining objects\n",
    "\n",
    "zip can be used to combine object.     \n",
    "\n",
    "Python also has built-in specialised container datatypes as alternatives to general purpose dict, list, set and turple.    \n",
    "Notable:     \n",
    "namedtuple: tuple subclasses with named fields     \n",
    "deque: list-like container with fast appends and pops        \n",
    "Counter: dict for counting hashable objects       \n",
    "OrderedDict: dict that retains order of entries            \n",
    "defaultdict: dict that calls a factory function to supply missing values.          \n",
    "\n",
    "The itertools are functional tools for creating and using iterators.        \n",
    "Notable:     \n",
    "Infinite iterators: count, cycle, repeat      \n",
    "Finite iterators: accumulate, chain, zip_longest      \n",
    "Combination generators: product, permutations, combinations       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bulbasaur', 45), ('Charmander', 39), (' Squirtle', 44)]\n"
     ]
    }
   ],
   "source": [
    "names = [\"Bulbasaur\", \"Charmander\", \" Squirtle\"]\n",
    "hps = [45, 39, 44]\n",
    "\n",
    "# inefficient\n",
    "combined = []\n",
    "\n",
    "for i, pokemon in enumerate(names):\n",
    "    combined.append((pokemon, hps[i]))\n",
    "    \n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'zip'>\n"
     ]
    }
   ],
   "source": [
    "# using zip\n",
    "# uneven zip: will stop once the shortest list is exhausted\n",
    "combined_zip = zip(names, hps)\n",
    "# return a \"zip\" obj\n",
    "print(type(combined_zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bulbasaur', 45), ('Charmander', 39), (' Squirtle', 44)]\n"
     ]
    }
   ],
   "source": [
    "# the obj \"zip\" has to be unpacked into a list to see the contents\n",
    "combined_zip_list = [*combined_zip]\n",
    "print(combined_zip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Grass': 1, 'Dark': 2, 'Fire': 2, 'Water': 2, 'Steel': 2, 'Dragon': 1}\n"
     ]
    }
   ],
   "source": [
    "# frequency counting with loop\n",
    "poke_types = [\"Grass\", \"Dark\", \"Fire\", \"Water\", \"Steel\", \"Dragon\", \"Dark\", \"Water\", \"Steel\", \"Fire\"]\n",
    "\n",
    "# normal way\n",
    "type_count = {}\n",
    "\n",
    "for poke_type in poke_types:\n",
    "    if poke_type not in type_count:\n",
    "        type_count[poke_type] = 1\n",
    "    else: type_count[poke_type] += 1\n",
    "        \n",
    "print(type_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Dark': 2, 'Fire': 2, 'Water': 2, 'Steel': 2, 'Grass': 1, 'Dragon': 1})\n"
     ]
    }
   ],
   "source": [
    "# using collections.Counter()\n",
    "from collections import Counter\n",
    "\n",
    "type_counts_counter = Counter(poke_types)\n",
    "print(type_counts_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Grass', 'Dark'), ('Grass', 'Fire'), ('Grass', 'Water'), ('Grass', 'Steel'), ('Grass', 'Dragon'), ('Dark', 'Fire'), ('Dark', 'Water'), ('Dark', 'Steel'), ('Dark', 'Dragon'), ('Fire', 'Water'), ('Fire', 'Steel'), ('Fire', 'Dragon'), ('Water', 'Steel'), ('Water', 'Dragon'), ('Steel', 'Dragon')]\n"
     ]
    }
   ],
   "source": [
    "# Suppose we want all combinations pairs of type possible\n",
    "combos = []\n",
    "\n",
    "for x in poke_types:\n",
    "    for y in poke_types:\n",
    "        if x==y:\n",
    "            continue\n",
    "        if ((x,y) not in combos) & ((y,x) not in combos):\n",
    "            combos.append((x,y))\n",
    "            \n",
    "print(combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'itertools.combinations'>\n",
      "[('Grass', 'Dark'), ('Grass', 'Fire'), ('Grass', 'Water'), ('Grass', 'Steel'), ('Grass', 'Dragon'), ('Grass', 'Dark'), ('Grass', 'Water'), ('Grass', 'Steel'), ('Grass', 'Fire'), ('Dark', 'Fire'), ('Dark', 'Water'), ('Dark', 'Steel'), ('Dark', 'Dragon'), ('Dark', 'Dark'), ('Dark', 'Water'), ('Dark', 'Steel'), ('Dark', 'Fire'), ('Fire', 'Water'), ('Fire', 'Steel'), ('Fire', 'Dragon'), ('Fire', 'Dark'), ('Fire', 'Water'), ('Fire', 'Steel'), ('Fire', 'Fire'), ('Water', 'Steel'), ('Water', 'Dragon'), ('Water', 'Dark'), ('Water', 'Water'), ('Water', 'Steel'), ('Water', 'Fire'), ('Steel', 'Dragon'), ('Steel', 'Dark'), ('Steel', 'Water'), ('Steel', 'Steel'), ('Steel', 'Fire'), ('Dragon', 'Dark'), ('Dragon', 'Water'), ('Dragon', 'Steel'), ('Dragon', 'Fire'), ('Dark', 'Water'), ('Dark', 'Steel'), ('Dark', 'Fire'), ('Water', 'Steel'), ('Water', 'Fire'), ('Steel', 'Fire')]\n"
     ]
    }
   ],
   "source": [
    "# using itertools\n",
    "from itertools import combinations\n",
    "combos_obj = combinations(poke_types, 2)\n",
    "print(type(combos_obj))\n",
    "combos = [*combos_obj]\n",
    "print(combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Set Theory\n",
    "\n",
    "If we want to compare similiarity and differences between the contents of 2 objects, we can use set theory.      \n",
    "\n",
    "Built-in \"set\" datatype with accompanying methods:          \n",
    "intersection(): all elements that are in both sets       \n",
    "difference(): all elements in one set but not the other        \n",
    "symmetric_difference(): all elements in exactly one set     \n",
    "union(): all elements that are in either set       \n",
    "\n",
    "we can consider to store data in set datatype if we wish to compare them.       \n",
    "they also have the ability to quickly check if a value exist within its memeber using \"in\" operator.     \n",
    "\n",
    "A set is defined as a collection of distinct elements. We can use a set to collect unique items from an existing object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Squirtle']\n"
     ]
    }
   ],
   "source": [
    "list_a = [\"Bulbasaur\", \"Charmander\", \"Squirtle\"]\n",
    "list_b = [\"Caterpie\", \"Pidgey\", \"Squirtle\"]\n",
    "\n",
    "# find intersec\n",
    "# inefficent\n",
    "in_common = []\n",
    "\n",
    "for pokemon_a in list_a:\n",
    "    for pokemon_b in list_b:\n",
    "        if pokemon_a == pokemon_b:\n",
    "            in_common.append(pokemon_a)\n",
    "            \n",
    "print(in_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bulbasaur', 'Squirtle', 'Charmander'}\n"
     ]
    }
   ],
   "source": [
    "# using the set datatype\n",
    "set_a = set(list_a)\n",
    "print(set_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pidgey', 'Squirtle', 'Caterpie'}\n"
     ]
    }
   ],
   "source": [
    "set_b = set(list_b)\n",
    "print(set_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Squirtle'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_a.intersection(set_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bulbasaur', 'Charmander'}\n",
      "{'Pidgey', 'Caterpie'}\n"
     ]
    }
   ],
   "source": [
    "# in set_a but not in set_b\n",
    "print(set_a.difference(set_b))\n",
    "# in set_b but not in set_a\n",
    "print(set_b.difference(set_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bulbasaur', 'Caterpie', 'Charmander', 'Pidgey'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_a.symmetric_difference(set_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bulbasaur', 'Caterpie', 'Charmander', 'Pidgey', 'Squirtle'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_a.union(set_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grass', 'Dark', 'Fire', 'Water', 'Steel', 'Dragon']\n"
     ]
    }
   ],
   "source": [
    "# collect unique items\n",
    "\n",
    "#inefficient\n",
    "unique_types = []\n",
    "\n",
    "for prim_type in poke_types:\n",
    "    if prim_type not in unique_types:\n",
    "        unique_types.append(prim_type)\n",
    "        \n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Steel', 'Grass', 'Dragon', 'Fire', 'Water', 'Dark'}\n"
     ]
    }
   ],
   "source": [
    "# using set\n",
    "unique_type_set = set(poke_types)\n",
    "print(unique_type_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Eliminating loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[317, 150, 320]\n"
     ]
    }
   ],
   "source": [
    "poke_stats = [\n",
    "    [90, 92, 75, 60],\n",
    "    [25, 20, 15, 90],\n",
    "    [55, 130, 60, 75]\n",
    "]\n",
    "\n",
    "# sum of each row\n",
    "\n",
    "# for loop: inefficient\n",
    "totals = []\n",
    "for row in poke_stats:\n",
    "    totals.append(sum(row))\n",
    "    \n",
    "print(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[317, 150, 320]\n",
      "[317, 150, 320]\n"
     ]
    }
   ],
   "source": [
    "# list comprehension\n",
    "# faster\n",
    "totals_comp = [sum(row) for row in poke_stats]\n",
    "print(totals_comp)\n",
    "\n",
    "# built-in map()\n",
    "# even faster\n",
    "totals_comp = [*map(sum, poke_stats)]\n",
    "print(totals_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.25, 37.5, 80.0]\n"
     ]
    }
   ],
   "source": [
    "# use numpy\n",
    "poke_stats = np.array([\n",
    "    [90, 92, 75, 60],\n",
    "    [25, 20, 15, 90],\n",
    "    [55, 130, 60, 75]\n",
    "])\n",
    "\n",
    "# avg of row\n",
    "# inefficent\n",
    "avgs = []\n",
    "for row in poke_stats:\n",
    "    avg = np.mean(row)\n",
    "    avgs.append(avg)\n",
    "print(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.25 37.5  80.  ]\n"
     ]
    }
   ],
   "source": [
    "# vectorisation\n",
    "avgs_np = poke_stats.mean(axis=1)\n",
    "print(avgs_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Writing better loops\n",
    "\n",
    "Note, some loops here can be eliminated, but are here for demonstration purposes.      \n",
    "\n",
    "1) Understand what is being done with each loop iteration      \n",
    "2) Move 1-time calcuations outside (above) the loop     \n",
    "3) Use holistic conversion outside (below) loop (use a map())      \n",
    "4) anything that is done once should be outside the loop.      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absol's attack: 130 > average: 69.0!\n",
      "Aron's attack: 70 > average: 69.0!\n"
     ]
    }
   ],
   "source": [
    "names = [\"Absol\", \"Aron\", \"Jynx\", \"Natu\", \"Onix\"]\n",
    "attacks = np.array([130, 70, 50, 50, 45])\n",
    "\n",
    "# want name of pokemon with attack > avg of all attack\n",
    "\n",
    "# loop\n",
    "for pokemon, attack in zip(names, attacks):\n",
    "    total_attack_avg = attacks.mean() # bad, should move out)\n",
    "    if attack > total_attack_avg:\n",
    "        print(\n",
    "        \"{}'s attack: {} > average: {}!\"\n",
    "        .format(pokemon, attack, total_attack_avg)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Pikachu', False, 1], ['Squirtle', False, 1], ['Articuno', True, 1]]\n",
      "[['Pikachu', False, 1], ['Squirtle', False, 1], ['Articuno', True, 1]]\n"
     ]
    }
   ],
   "source": [
    "# not-so-holistic conversions\n",
    "names = [\"Pikachu\", \"Squirtle\", \"Articuno\"]\n",
    "legend_status = [False, False, True]\n",
    "generations = [1,1,1]\n",
    "\n",
    "poke_data = []\n",
    "for poke_tuple in zip(names, legend_status, generations):\n",
    "    poke_list = list(poke_tuple)\n",
    "    poke_data.append(poke_list)\n",
    "    \n",
    "print(poke_data)\n",
    "\n",
    "# holistic\n",
    "poke_data_tuples = []\n",
    "for poke_tuple in zip(names, legend_status, generations):\n",
    "    poke_data_tuples.append(poke_tuple)\n",
    "poke_data = [*map(list, poke_data_tuples)]\n",
    "print(poke_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 pandas iteration\n",
    "\n",
    "1) .iterrows()      \n",
    "Use test_df.iterrows(): create list of tuple (index, Series_row_data)     \n",
    "\n",
    "2) .itertuples()     \n",
    "often more efficient than .iterrows().     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n",
       "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n",
       "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n",
       "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n",
       "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n",
       "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n",
       "\n",
       "   RankPlayoffs    G   OOBP   OSLG  \n",
       "0           NaN  162  0.317  0.415  \n",
       "1           5.0  162  0.306  0.378  \n",
       "2           4.0  162  0.315  0.403  \n",
       "3           NaN  162  0.331  0.428  \n",
       "4           NaN  162  0.335  0.424  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_df = pd.read_csv(\"../python_basics/data/baseball_stats.csv\")\n",
    "baseball_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_df_copy = baseball_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate win percent\n",
    "def calc_win_perc(wins, games_played):\n",
    "    win_perc = wins/games_played\n",
    "    return np.round(win_perc,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "      <th>WP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n",
       "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n",
       "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n",
       "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n",
       "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n",
       "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n",
       "\n",
       "   RankPlayoffs    G   OOBP   OSLG    WP  \n",
       "0           NaN  162  0.317  0.415  0.50  \n",
       "1           5.0  162  0.306  0.378  0.58  \n",
       "2           4.0  162  0.315  0.403  0.57  \n",
       "3           NaN  162  0.331  0.428  0.43  \n",
       "4           NaN  162  0.335  0.424  0.38  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding win perc to DataFrame\n",
    "\n",
    "#inefficient\n",
    "win_perc_list = []\n",
    "\n",
    "for i in range(len(baseball_df_copy)):\n",
    "    row = baseball_df_copy.iloc[i]\n",
    "    wins = row[\"W\"]\n",
    "    games_played = row[\"G\"]\n",
    "    win_perc = calc_win_perc(wins, games_played)\n",
    "    win_perc_list.append(win_perc)\n",
    "    \n",
    "baseball_df_copy[\"WP\"]=win_perc_list\n",
    "baseball_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "      <th>WP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n",
       "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n",
       "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n",
       "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n",
       "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n",
       "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n",
       "\n",
       "   RankPlayoffs    G   OOBP   OSLG    WP  \n",
       "0           NaN  162  0.317  0.415  0.50  \n",
       "1           5.0  162  0.306  0.378  0.58  \n",
       "2           4.0  162  0.315  0.403  0.57  \n",
       "3           NaN  162  0.331  0.428  0.43  \n",
       "4           NaN  162  0.335  0.424  0.38  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_df_copy1 = baseball_df.copy()\n",
    "\n",
    "# using iterrows() to iterate DataFrame\n",
    "win_perc_list = []\n",
    "# iterrows return each DF row as a tuple of (index, Series)\n",
    "for i, row in baseball_df_copy1.iterrows():\n",
    "    wins = row[\"W\"]\n",
    "    games_played = row[\"G\"]\n",
    "    win_perc = calc_win_perc(wins, games_played)\n",
    "    win_perc_list.append(win_perc)\n",
    "    \n",
    "baseball_df_copy1[\"WP\"] = win_perc_list\n",
    "baseball_df_copy1.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .itertuples\n",
    "baseball_df_copy2 = baseball_df.copy()\n",
    "\n",
    "# behaves like tuple but have fields accessible using attribute lookup\n",
    "for row_namedtuple in baseball_df_copy2.itertuples():\n",
    "    print(row_namedtuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231\n",
      "WSA\n"
     ]
    }
   ],
   "source": [
    "print(row_namedtuple.Index)\n",
    "print(row_namedtuple.Team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 pandas alternative to looping\n",
    "\n",
    "use the .apply() method.      \n",
    "This func acts like .map(), but apply to entire dataframe. (axis = 0 for col, 1 for row)     \n",
    "Can be used with lambda func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_df_copy3 = baseball_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_run_diff(runs_scored, runs_allowed):\n",
    "    run_diff = runs_scored - runs_allowed\n",
    "    return run_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "      <th>RD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "      <td>-146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>PHI</td>\n",
       "      <td>NL</td>\n",
       "      <td>1962</td>\n",
       "      <td>705</td>\n",
       "      <td>759</td>\n",
       "      <td>81</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>PIT</td>\n",
       "      <td>NL</td>\n",
       "      <td>1962</td>\n",
       "      <td>706</td>\n",
       "      <td>626</td>\n",
       "      <td>93</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>SFG</td>\n",
       "      <td>NL</td>\n",
       "      <td>1962</td>\n",
       "      <td>878</td>\n",
       "      <td>690</td>\n",
       "      <td>103</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.278</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>STL</td>\n",
       "      <td>NL</td>\n",
       "      <td>1962</td>\n",
       "      <td>774</td>\n",
       "      <td>664</td>\n",
       "      <td>84</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>WSA</td>\n",
       "      <td>AL</td>\n",
       "      <td>1962</td>\n",
       "      <td>599</td>\n",
       "      <td>716</td>\n",
       "      <td>60</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1232 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team League  Year   RS   RA    W    OBP    SLG     BA  Playoffs  \\\n",
       "0     ARI     NL  2012  734  688   81  0.328  0.418  0.259         0   \n",
       "1     ATL     NL  2012  700  600   94  0.320  0.389  0.247         1   \n",
       "2     BAL     AL  2012  712  705   93  0.311  0.417  0.247         1   \n",
       "3     BOS     AL  2012  734  806   69  0.315  0.415  0.260         0   \n",
       "4     CHC     NL  2012  613  759   61  0.302  0.378  0.240         0   \n",
       "...   ...    ...   ...  ...  ...  ...    ...    ...    ...       ...   \n",
       "1227  PHI     NL  1962  705  759   81  0.330  0.390  0.260         0   \n",
       "1228  PIT     NL  1962  706  626   93  0.321  0.394  0.268         0   \n",
       "1229  SFG     NL  1962  878  690  103  0.341  0.441  0.278         1   \n",
       "1230  STL     NL  1962  774  664   84  0.335  0.394  0.271         0   \n",
       "1231  WSA     AL  1962  599  716   60  0.308  0.373  0.250         0   \n",
       "\n",
       "      RankSeason  RankPlayoffs    G   OOBP   OSLG   RD  \n",
       "0            NaN           NaN  162  0.317  0.415   46  \n",
       "1            4.0           5.0  162  0.306  0.378  100  \n",
       "2            5.0           4.0  162  0.315  0.403    7  \n",
       "3            NaN           NaN  162  0.331  0.428  -72  \n",
       "4            NaN           NaN  162  0.335  0.424 -146  \n",
       "...          ...           ...  ...    ...    ...  ...  \n",
       "1227         NaN           NaN  161    NaN    NaN  -54  \n",
       "1228         NaN           NaN  161    NaN    NaN   80  \n",
       "1229         1.0           2.0  165    NaN    NaN  188  \n",
       "1230         NaN           NaN  163    NaN    NaN  110  \n",
       "1231         NaN           NaN  162    NaN    NaN -117  \n",
       "\n",
       "[1232 rows x 16 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_diffs_apply = baseball_df_copy3.apply(lambda row: calc_run_diff(row[\"RS\"], row[\"RA\"]), axis=1)\n",
    "baseball_df_copy3[\"RD\"] = run_diffs_apply\n",
    "baseball_df_copy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_df_copy4 = baseball_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# grab any col as np array\n",
    "wins_np = baseball_df_copy4[\"W\"].values\n",
    "print(type(wins_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 81  94  93 ... 103  84  60]\n"
     ]
    }
   ],
   "source": [
    "print(wins_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  46,  100,    7, ...,  188,  110, -117])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorisation\n",
    "baseball_df_copy4[\"RS\"].values - baseball_df_copy4[\"RA\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n",
      "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n",
      "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n",
      "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n",
      "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n",
      "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n",
      "\n",
      "   RankPlayoffs    G   OOBP   OSLG   RD  \n",
      "0           NaN  162  0.317  0.415   46  \n",
      "1           5.0  162  0.306  0.378  100  \n",
      "2           4.0  162  0.315  0.403    7  \n",
      "3           NaN  162  0.331  0.428  -72  \n",
      "4           NaN  162  0.335  0.424 -146  \n"
     ]
    }
   ],
   "source": [
    "run_diffs_np = baseball_df_copy4[\"RS\"].values - baseball_df_copy4[\"RA\"].values\n",
    "baseball_df_copy4[\"RD\"] = run_diffs_np\n",
    "print(baseball_df_copy4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wrote a function in python, how do we know the implementation is correct ?    \n",
    "Easiest way is to open an interpreter, test the function on a few arguments and check whether the return value is correct.     \n",
    "\n",
    "This is actually not very efficient.       \n",
    "\n",
    "One example below to test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample function for a two-col data\n",
    "# func return None if has missing area or tab separator\n",
    "def row_to_list(row):\n",
    "    row = row.rstrip(\"\\n\")\n",
    "    separated_entries = row.split(\"\\t\")\n",
    "    if len(separated_entries) == 2 and \"\" not in separated_entries:\n",
    "        return separated_entries\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,081', '314,942']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_to_list(\"2,081\\t314,942\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_list(\"\\t293,410\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many python library for writing unit tests such as pytest, unittest, nosetests and doctest.    \n",
    "We use pytest here becasue it is easy to use, most popular and has all essential features.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Unit test and mini-project outline/pipeline\n",
    "\n",
    "In this section, we will have raw (tabular) data on housing area and price, and have to create a cleaned data using some func. These cleaned data is then used compute features. Then they are used to create predictive module.      \n",
    "\n",
    "i.e.      \n",
    "raw data -> clean-up (func) -> clean data -> create feature (func) -> feature -> modeling (func) -> predictive model ---> housing area/price.    \n",
    "\n",
    "What is a unit?     \n",
    "Small, independent piece of code, can be func or class.     \n",
    "\n",
    "Integration test checks multiple units at the same time, and not independently. (e.g. input raw data, check feature)      \n",
    "End to end test checks the whole pipeline at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Unit testing basics\n",
    "\n",
    "(source code for this part is in ../python_basics/DataCamp_UnitTest/src/data/test_row_to_list.py)\n",
    "\n",
    "To start unit test with pytest (for the above func), we will first create a file called test_row_to_list.py     \n",
    "When pythest sees  a filename start with \"test_\", it understands that this is not an usual python file, for a speical one containing unit test.     \n",
    "\n",
    "Files holding unit tests are also called test modules, and we just created our first test module.    \n",
    "In the test module \"test_row_to_list.py\", we first import pytest, then import func undertest.    \n",
    "\n",
    "A unit test is written as a python func, whose name starts with a \"test_\", just like the test module. So pythest can tell this is a unit test and not a ordinary python func. The unit test usually corresponds to exactly one entry in the argument and return value table for row_to_list(). The unit test checks whether row_to_list() has the expected return value when called on this particular argument.    \n",
    "\n",
    "To run the test module, run \"pytest test_row_to_list.py\" (under conda env due to package availablity).      \n",
    "\n",
    "The unit tests script also serve as documentation. If a collaborator didn't know this func purpose, they can recreate the argument <--> return value table, by looking at the bool expression used in the assert statements. The table will give then a good hint about what the func does.     \n",
    "\n",
    "Unit test also increase trust in a package, as users can run the unit tests and verify that the func work. We can setup a Continuous Integration or IC to run all unit test when any code is pushed to source repository. If any unit test failed, it reject the changes and informs the devs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assert statement can take a second argument called message:     \n",
    "\n",
    "assert boolean_expression, message      \n",
    "\n",
    "The message is only printed when the assert statement raises an assertion error.    \n",
    "\n",
    "It is recommended to include a message with assertions because of readibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "One is not equal to two!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-674636f6e006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"One is not equal to two!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: One is not equal to two!"
     ]
    }
   ],
   "source": [
    "assert 1 == 2, \"One is not equal to two!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware of float return values:      \n",
    "\n",
    "Due to memory and rounding, we should not use the usual way to compare floats in the assertion statement.    \n",
    "\n",
    "We should use the pytest.approx() to wrapp expected return values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 0.1 +0.1 == 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Usual way",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-025aa42508ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#usual way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"Usual way\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Usual way"
     ]
    }
   ],
   "source": [
    "#usual way\n",
    "assert 0.1 + 0.1 +0.1 == 0.3 , \"Usual way\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this for float\n",
    "assert 0.1 + 0.1 + 0.1 == pytest.approx(0.3)\n",
    "# empty output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also works on np array\n",
    "assert np.array([0.1+0.1, 0.1+0.1+0.1]) == pytest.approx(np.array([0.2,0.3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have used assert to check if a func returns the expected value. Some func may not return anythingm but rather raise an exception when called on certain arg.     \n",
    "\n",
    "We can also test whether this func raises ValueError when 1d array is used as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_training_and_testing_sets(data_array):\n",
    "    dim = data_array.ndim\n",
    "    if dim != 2:\n",
    "        raise ValueError(\"Argument data_array must be two dimensional. Got {0} dimensional array instead!\".format(dim))\n",
    "    num_rows = data_array.shape[0]\n",
    "    if num_rows < 2:\n",
    "        raise ValueError(\"Argument data_array must have at least 2 rows, it actually has just {0}\".format(num_rows))\n",
    "    num_training = int(0.75 * data_array.shape[0])\n",
    "    permuted_indices = np.random.permutation(data_array.shape[0])\n",
    "    return data_array[permuted_indices[:num_training], :], data_array[permuted_indices[num_training:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  2081, 314942],\n",
       "        [  1059, 186606]]), array([[  1148, 206186]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input must be 2d, if not raise a ValueError\n",
    "example_argument = np.array([[2081, 314942],\n",
    "                            [1059, 186606],\n",
    "                            [1148, 206186],\n",
    "                            ]\n",
    "                           )\n",
    "\n",
    "split_into_training_and_testing_sets(example_argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument data_array must be two dimensional. Got 1 dimensional array instead!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9aef95cd93b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexample_argument_1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2081\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m314942\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1059\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m186606\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1148\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m206186\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msplit_into_training_and_testing_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_argument_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-2a035d1325cc>\u001b[0m in \u001b[0;36msplit_into_training_and_testing_sets\u001b[0;34m(data_array)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Argument data_array must be two dimensional. Got {0} dimensional array instead!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_rows\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument data_array must be two dimensional. Got 1 dimensional array instead!"
     ]
    }
   ],
   "source": [
    "# input must be 2d, if not raise a ValueError\n",
    "example_argument_1d = np.array([2081,314942, 1059, 186606, 1148, 206186])\n",
    "\n",
    "split_into_training_and_testing_sets(example_argument_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context manager\n",
    "# Do not run\n",
    "\n",
    "# context manager runs some code before entering and exiting the context\n",
    "\n",
    "with context_manager:\n",
    "    # <-- run some code on entering context\n",
    "    print(\"This is part of the context\")\n",
    "    #<--- run some code on exiting context\n",
    "\n",
    "with pytest.raises(ValueError): #context manager\n",
    "    # <- Does nothing on entering the context\n",
    "    print(\"This is part of the context\")\n",
    "    # <- If context raised ValueError, silence it\n",
    "    # <- if the context did not raise ValueError, raise an exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pytest.raises(ValueError):\n",
    "    raise ValueError # context exits with ValueError\n",
    "    # <--- pytest.raises(ValueError) silences it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Failed",
     "evalue": "DID NOT RAISE <class 'ValueError'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailed\u001b[0m                                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0510db8df69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpytest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraises\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/_pytest/python_api.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0mfail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexcinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/_pytest/outcomes.py\u001b[0m in \u001b[0;36mfail\u001b[0;34m(msg, pytrace)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \"\"\"\n\u001b[1;32m    127\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFailed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpytrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailed\u001b[0m: DID NOT RAISE <class 'ValueError'>"
     ]
    }
   ],
   "source": [
    "with pytest.raises(ValueError):\n",
    "    pass # context exits without raising a ValueError\n",
    "    # <-- pytest.raises(ValueError) raises Failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many tests shoud we write for a func ?     \n",
    "Best practice is to pick a few from each of the categories:     \n",
    "1) Bad argument\n",
    "2) Special argument\n",
    "3) Normal argument\n",
    "\n",
    "If a func is tested in all these category, it can be considered as well-tested func.    \n",
    "\n",
    "For the example of split_into_training_and_testing_sets() function, examples:      \n",
    "1) Bad argument     \n",
    "Bad arguments are arguments for which the func raises an exception instead of returning a value.     \n",
    "1 dimension array is a bad argument.      \n",
    "\n",
    "2) Special argument     \n",
    "2 types:    \n",
    "Boundary values    \n",
    "For some argument values, func uses speical logic       \n",
    "\n",
    "3) Normal argument    \n",
    "Anything that is not Bad or Speical argument.       \n",
    "\n",
    "Caveat:    \n",
    "Not all func have bad or speical arguments, in this case, just ignore those category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Driven Development (TDD):**     \n",
    "\n",
    "step 1: Write unit tests and fix requirements     \n",
    "As we write unit test, we think more about the requirement of this func.    \n",
    "\n",
    "step 2: run tests and watch it fail      \n",
    "since func has not exist yet.\n",
    "\n",
    "step 3: implement func and run test again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Organize set of tests\n",
    "\n",
    "My each corresponding my_module.py, there should be a corresponding test_my_module.py     \n",
    "So while we have a folder called src (for source code), there will be a folder called test that mirror its structure.    \n",
    "\n",
    "We can use a construc called test class to organise the different test class.     \n",
    "\n",
    "We can run all test by go to the folder and type \"pytest\", it will recurse into directory subtree and run all tests:   \n",
    "Filenames starting with test_    \n",
    "within it identifies classname starting with Test     \n",
    "within it identifies func name start with test_      \n",
    "\n",
    "pytest -x: stop after first failure.    \n",
    "\n",
    "pytest file_path_to_test_module: also works     \n",
    "\n",
    "During testing, pytest assign a node ID to every test class and unit test that it encounters:    \n",
    "Node ID of a test class: (path to test module)::(test class name)     \n",
    "Node ID of an unit test: (path to test module)::(test class name)::(unit test name)        \n",
    "\n",
    "pytest NodeID: only run the specific tests       \n",
    "\n",
    "keyword expression     \n",
    "pytest -k \"pattern\": run all tests whose node ID matches the pattern     \n",
    "Python logical operator also works in keyword expression e.g. not in etc.      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Expected to fail\n",
    "\n",
    "Sometimes we know certain test is gonna fail (e.g. actual func not yet implemented, but we wrote some test cases). we can use \"xfail\" decorator. The decorator goes on top of a test, and it starts with @:    \n",
    "@pytest.mark.xfail    \n",
    "\n",
    "This will make the test suite still green.    \n",
    "\n",
    "we can also use     \n",
    "@pytest.mark.skipif(bool_exp)    \n",
    "if true, this test is skipped     \n",
    "\n",
    "When integrating with github, use Travis CI, and create a travis.ymml file, and also codecov can show how much percent the code (no. of lines) are tested.     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for illustration, do not run\n",
    "class TestTrainModel(object):\n",
    "    @pytest.mark.xfail(reason=\"Using TDD, func is not implemented\")\n",
    "    def test_on_linear_data(self):\n",
    "        ...\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for illustration, do not run\n",
    "class TestTrainModel(object):\n",
    "    @pytest.mark.skipif(sys.version_info > (2,7), reason=\"requires python 2.7\")\n",
    "    def test_on_linear_data(self):\n",
    "        \"\"\"Only runs on python 2.7 or lower\"\"\"\n",
    "        ...\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Advanced unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some functions whose tests require more than assert statement. One example is shown below. The func first apply row_to_list to rows then convert to int. These will filter out bad data and wrote the result to the clean file.    \n",
    "preprocess() needs a raw datafile in the enviroment to work properly. When we call the func, it modifies the environment by creating a clean data file.     \n",
    "\n",
    "We can create a test for this func called test_on_raw_data().    \n",
    "\n",
    "Need to setup an env for the assert, then teardown to restore to a clean state env for the next test    \n",
    "So the new work flow goes like:      \n",
    "setup -> assert -> teardown      \n",
    "\n",
    "In pytest, the setup and teardown is placed outside the test, in a function called a fixture.     \n",
    "A fixture is a function which has the pytest.fixure decorator.     \n",
    "The first section is the setup. Then the func return the data that the test needs. The test can access this data by calling the fixure passed as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_data_file_path, clean_data_file_path):\n",
    "    with open(raw_data_file_path, \"r\") as input_file:\n",
    "        rows = input_file.readlines()\n",
    "    with open(clean_data_file_path, \"w\") as output_file:\n",
    "        for row in rows:\n",
    "            row_as_list = row_to_list(row)\n",
    "            if row_as_list is None:\n",
    "                continue\n",
    "            area = convert_to_int(row_as_list[0])\n",
    "            price = convert_to_int(row_as_list[1])\n",
    "            if area is None or price is None:\n",
    "                continue\n",
    "            output_file.write(\"{0}\\t{1}\\n\".format(area, price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_raw_data():\n",
    "    #setup: create the raw data file\n",
    "    # bring the env to a state where testing can begin\n",
    "    preprocess(raw_data_path, clean_data_file_path)\n",
    "    with open(clean_data_file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        first_line = lines[0]\n",
    "        assert first_line == \"1801\\t201411\\n\"\n",
    "        second_line = lines[1]\n",
    "        assert second_line == \"2002\\t333209\\n\"\n",
    "        # Teardown: remove row and clean data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytest.fixure structure\n",
    "\n",
    "@pytest.fixure\n",
    "\n",
    "def my_fixure():\n",
    "    # Do setup here\n",
    "    yield data \n",
    "    # Do teardown here\n",
    "    \n",
    "    \n",
    "def test_something(my_fixure):\n",
    "    ...\n",
    "    data = my_fixure\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.\n",
    "\n",
    "#Fixure\n",
    "@pytest.fixture\n",
    "def raw_and_clean_data_file():\n",
    "    raw_data_file_path = \"raw.txt\"\n",
    "    clean_data_file_path = \"clean.txt\"\n",
    "    with open(\"raw.txt\", \"w\") as f:\n",
    "        f.write(\"1,801\\t201,411\\n\"\n",
    "               \"1,767565,112\\n\"\n",
    "               \"2,002\\t333,209\\n\"\n",
    "               \"1990\\t7822,911\\n\"\n",
    "               \"1,285\\t389129\\n\")\n",
    "    yield raw_data_file_path, clean_data_file_path\n",
    "    #teardown\n",
    "    os.remove(raw_data_file_path)\n",
    "    os.remove(clean_data_file_path)\n",
    "    \n",
    "    \n",
    "#test\n",
    "def test_on_raw_data(row_and_clean_data_file):\n",
    "    raw_path, clean_path = raw_and_clean_data_file\n",
    "    preprocess(raw_path, clean_path)\n",
    "    with open(clean_data_file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        first_line = lines[0]\n",
    "        assert first_line == \"1801\\t201411\\n\"\n",
    "        second_line = lines[1]\n",
    "        assert second_line == \"2002\\t333209\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use tmpdir\n",
    "@pytest.fixture\n",
    "def raw_and_clean_data_file(tmpdir):\n",
    "    raw_data_file_path = tempdir.join(\"raw.txt\")\n",
    "    clean_data_file_path = tmpdir.join(\"clean.txt\")\n",
    "    with open(\"raw.txt\", \"w\") as f:\n",
    "        f.write(\"1,801\\t201,411\\n\"\n",
    "               \"1,767565,112\\n\"\n",
    "               \"2,002\\t333,209\\n\"\n",
    "               \"1990\\t7822,911\\n\"\n",
    "               \"1,285\\t389129\\n\")\n",
    "    yield raw_data_file_path, clean_data_file_path\n",
    "    #no teardown needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
